{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Text Extraction for CV Analysis\n",
    "\n",
    "This script processes CVs stored in PDF format, organized into directories by job categories.\n",
    "\n",
    "## Part I: Text Extraction with PyPDF2\n",
    "\n",
    "###  fitz Library\n",
    "\n",
    "- `fitz` is a Pure-Python library built as a PDF toolkit. It is capable of extracting text from PDFs that contain selectable text.\n",
    "\n",
    "### Workflow\n",
    "\n",
    "1. **Directory Traversal**: The script walks through each directory starting from the specified base path, processing only `.pdf` files.\n",
    "\n",
    "2. **Text Extraction**: For each PDF, the script attempts to extract text using PyPDF2. It iterates through all pages of the document, concatenating the text it finds.\n",
    "\n",
    "3. **Skipped Documents**: If fitz is unable to extract text, which suggests the document may contain scanned images instead of text, the file is noted and skipped.\n",
    "\n",
    "4. **Output**: Extracted text is printed to the console. For production use, this would typically be redirected to save in a file or database.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- The script does not handle OCR and will not extract text from scanned image PDFs.\n",
    "- It assumes all text-based content in a PDF is extractable, which may not be true for PDFs with complex encodings or security restrictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import csv\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Perform basic text cleaning\n",
    "    text = text.replace('\\n', ' ')  # Replace new lines with spaces\n",
    "    text = ' '.join(text.split())   # Remove extra spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path, writer):\n",
    "    # Open the PDF file\n",
    "    with fitz.open(pdf_path) as pdf:\n",
    "        # Concatenate text from all pages\n",
    "        full_text = ''\n",
    "        for page_num in range(len(pdf)):\n",
    "            page = pdf[page_num]\n",
    "            text = page.get_text()\n",
    "            full_text += text\n",
    "        \n",
    "        # Clean the extracted text\n",
    "        clean_full_text = clean_text(full_text)\n",
    "        \n",
    "        # Extract category and filename for CSV\n",
    "        category = os.path.basename(os.path.dirname(pdf_path))\n",
    "        filename = os.path.basename(pdf_path)\n",
    "        \n",
    "        # Write to CSV\n",
    "        writer.writerow([category, filename, clean_full_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_directories(base_path, output_csv_path):\n",
    "    # Open the output CSV file\n",
    "    with open(output_csv_path, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "        # Create a CSV writer\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        # Write header\n",
    "        csv_writer.writerow(['Category', 'Filename', 'Text'])\n",
    "        \n",
    "        # Walk through the base directory\n",
    "        for root, dirs, files in os.walk(base_path):\n",
    "            for file in files:\n",
    "                if file.endswith('.pdf'):\n",
    "                    # Construct the full path of the PDF file\n",
    "                    pdf_path = os.path.join(root, file)\n",
    "                    # Extract text and write to CSV\n",
    "                    extract_text_from_pdf(pdf_path, csv_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './data'\n",
    "output_csv_path = './processed_resumes.csv'\n",
    "process_pdf_directories(base_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # convert non-strings to  strings\n",
    "    text = str(text)\n",
    "    # Process the text with spaCy. This runs the entire pipeline.\n",
    "    doc = nlp(text)        \n",
    "    # Lemmatization, remove stopwords and punctuation and convert to lower case\n",
    "    tokens = [\n",
    "        token.lemma_.lower()\n",
    "        for token in doc\n",
    "        if not token.is_stop \n",
    "        and not token.is_punct\n",
    "        # Remove tokens that are only spaces\n",
    "        and not token.is_space\n",
    "    ]\n",
    "    \n",
    "    # Return preprocessed tokens\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_resumes.csv')\n",
    "df['Processed Text'] = df['Text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>Processed Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>10554236.pdf</td>\n",
       "      <td>ACCOUNTANT Summary Financial Accountant specia...</td>\n",
       "      <td>accountant summary financial accountant specia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>10674770.pdf</td>\n",
       "      <td>STAFF ACCOUNTANT Summary Highly analytical and...</td>\n",
       "      <td>staff accountant summary highly analytical det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>11163645.pdf</td>\n",
       "      <td>ACCOUNTANT Professional Summary To obtain a po...</td>\n",
       "      <td>accountant professional summary obtain positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>11759079.pdf</td>\n",
       "      <td>SENIOR ACCOUNTANT Experience Company Name June...</td>\n",
       "      <td>senior accountant experience company june 2011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>12065211.pdf</td>\n",
       "      <td>SENIOR ACCOUNTANT Professional Summary Senior ...</td>\n",
       "      <td>senior accountant professional summary senior ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category      Filename  \\\n",
       "0  ACCOUNTANT  10554236.pdf   \n",
       "1  ACCOUNTANT  10674770.pdf   \n",
       "2  ACCOUNTANT  11163645.pdf   \n",
       "3  ACCOUNTANT  11759079.pdf   \n",
       "4  ACCOUNTANT  12065211.pdf   \n",
       "\n",
       "                                                Text  \\\n",
       "0  ACCOUNTANT Summary Financial Accountant specia...   \n",
       "1  STAFF ACCOUNTANT Summary Highly analytical and...   \n",
       "2  ACCOUNTANT Professional Summary To obtain a po...   \n",
       "3  SENIOR ACCOUNTANT Experience Company Name June...   \n",
       "4  SENIOR ACCOUNTANT Professional Summary Senior ...   \n",
       "\n",
       "                                      Processed Text  \n",
       "0  accountant summary financial accountant specia...  \n",
       "1  staff accountant summary highly analytical det...  \n",
       "2  accountant professional summary obtain positio...  \n",
       "3  senior accountant experience company june 2011...  \n",
       "4  senior accountant professional summary senior ...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Marouane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemple for a job offer \n",
    "job_offer = \"We are looking for a data scientist with experience in machine learning and natural language processing\"\n",
    "# clean the job offer\n",
    "job_offer = preprocess_text(job_offer)\n",
    "\n",
    "\n",
    "# remove verb and pronouns from the job offer using spacy\n",
    "doc = nlp(job_offer)\n",
    "job_offer = ' '.join([token.lemma_ for token in doc if token.pos_ not in ['VERB', 'PRON']])\n",
    "# tokenize the job offer\n",
    "tokenized_job_offer = word_tokenize(job_offer)\n",
    "# return job offer simple text\n",
    "job_offer = ' '.join(tokenized_job_offer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using bm 25 rank the resumes based on the job offer\n",
    "def rank_resumes(job_offer, resumes):\n",
    "    tokenized_corpus = [word_tokenize(doc) for doc in resumes]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    tokenized_query = word_tokenize(job_offer)\n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "    return doc_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.12825729, 1.4847528 , 5.66822565, ..., 4.79884232, 2.48181935,\n",
       "       3.10907577])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_resumes(job_offer, df['Processed Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top 5 resumes\n",
    "top_resumes = df.iloc[rank_resumes(job_offer, df['Processed Text']).argsort()[::-1][:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Text</th>\n",
       "      <th>Processed Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>ENGINEERING</td>\n",
       "      <td>12011623.pdf</td>\n",
       "      <td>ENGINEERING AND QUALITY TECHNICIAN Career Over...</td>\n",
       "      <td>engineering quality technician career overview...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>AGRICULTURE</td>\n",
       "      <td>81042872.pdf</td>\n",
       "      <td>RESEARCH SCIENTIST Summary Highly motivated Re...</td>\n",
       "      <td>research scientist summary highly motivated re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>AVIATION</td>\n",
       "      <td>12144825.pdf</td>\n",
       "      <td>SOFTWARE ENGINEERING CO-OP Summary Highly skil...</td>\n",
       "      <td>software engineering co op summary highly skil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>ENGINEERING</td>\n",
       "      <td>28923650.pdf</td>\n",
       "      <td>THERMAL ENGINEERING INTERN Summary Graduating ...</td>\n",
       "      <td>thermal engineering intern summary graduating ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>DIGITAL-MEDIA</td>\n",
       "      <td>14036515.pdf</td>\n",
       "      <td>MONITOR TECH Summary Knowledge of modern offic...</td>\n",
       "      <td>monitor tech summary knowledge modern office m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Category      Filename  \\\n",
       "1464    ENGINEERING  12011623.pdf   \n",
       "296     AGRICULTURE  81042872.pdf   \n",
       "548        AVIATION  12144825.pdf   \n",
       "1526    ENGINEERING  28923650.pdf   \n",
       "1371  DIGITAL-MEDIA  14036515.pdf   \n",
       "\n",
       "                                                   Text  \\\n",
       "1464  ENGINEERING AND QUALITY TECHNICIAN Career Over...   \n",
       "296   RESEARCH SCIENTIST Summary Highly motivated Re...   \n",
       "548   SOFTWARE ENGINEERING CO-OP Summary Highly skil...   \n",
       "1526  THERMAL ENGINEERING INTERN Summary Graduating ...   \n",
       "1371  MONITOR TECH Summary Knowledge of modern offic...   \n",
       "\n",
       "                                         Processed Text  \n",
       "1464  engineering quality technician career overview...  \n",
       "296   research scientist summary highly motivated re...  \n",
       "548   software engineering co op summary highly skil...  \n",
       "1526  thermal engineering intern summary graduating ...  \n",
       "1371  monitor tech summary knowledge modern office m...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search pdfs and copy them to a new directory\n",
    "import shutil\n",
    "# Create a new directory to store the top resumes\n",
    "output_dir = 'top_resumes'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# use fileName to search for the pdfs in data directory\n",
    "for fileName in top_resumes['Filename']:\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file == fileName:\n",
    "                # Construct the full path of the PDF file\n",
    "                pdf_path = os.path.join(root, file)\n",
    "                # Copy the file to the output directory\n",
    "                shutil.copy(pdf_path, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
